{% set version = "0.7.0" %}
{% set number = 2 %}

{% if cuda_compiler_version in (None, "None", True, False) %}
  {% set cuda_major = 0 %}
  {% set extras = "" %}
  {% set build_number = number %}
  {% set build_string = 'core' %}
{% else %}
  {% set cuda_major = environ.get("cuda_compiler_version", "12.*").split(".")[0] | int %}
  {% set extras = "[sysctk" ~ cuda_major ~ "]" %}
  # Prioritize GPU builds
  {% set build_number = number + 200 %}
  {% set build_string = 'cuda' ~ cuda_major %}
{% endif %}

# {{ PYTHON }} is not resolved properly in multi-output recipes...
{% set PYTHON = "python" %}
{% set PYTHON = "$PREFIX/bin/python" %}  # [linux]
{% set PYTHON = "%PREFIX%\\python" %}  # [win]

# In addition to switching this to true, GPU tests require enabling the rapidsai channel in
# the build config
{% set is_gpu_available = false %}

package:
  name: nvmath-split
  version: {{ version }}

source:
  - url: https://github.com/NVIDIA/nvmath-python/archive/refs/tags/v{{ ".".join(version.split(".")[:3]) }}.tar.gz
    sha256: 822d20b5001536126153bb64ee7f1e53360a7d68cef0f97640a2bea9fd54aa40
    patches:
      - patches/0001-BUG-driver-load-failure-cpu.patch
      - patches/0001-TST-Catch-test-exceptions-when-cuda-driver-not-avail.patch
      - patches/0002-Update-example-for-Windows.patch  # [win]

build:
  number: {{ number }}
  skip: true  # [py < 310 or py > 313 or osx or ppc64le]
  # debugging skips:
  # skip: true  # [py != 310]

# Have certain top-level requirements so conda-smithy can render the correct variants
requirements:
  build:
    - {{ compiler('c') }}
    - {{ compiler('cuda') }}  # [cuda_compiler_version != "None"]
    - {{ compiler('cxx') }}
    - {{ stdlib('c') }}
  host:
    - python

outputs:

  - name: nvmath-python
    version: {{ version }}
    build:
      number: {{ build_number }}
      string: {{ build_string }}_py{{ py }}h{{ PKG_HASH }}_{{ build_number }}
      script:
        # do nothing for CUDA 11, as CUDA_PATH is set in the CI images
        - export CUDA_PATH=$BUILD_PREFIX/targets/x86_64-linux/   # [cuda_compiler_version != "None" and linux64]
        - export CUDA_PATH=$BUILD_PREFIX/targets/sbsa-linux/     # [cuda_compiler_version != "None" and aarch64]
        - set CUDA_PATH=%BUILD_PREFIX%\Library                   # [cuda_compiler_version != "None" and win64]
        - export CUDA_PATH=$PREFIX/targets/x86_64-linux/         # [cuda_compiler_version == "None" and linux64]
        - export CUDA_PATH=$PREFIX/targets/sbsa-linux/           # [cuda_compiler_version == "None" and aarch64]
        - set CUDA_PATH=%PREFIX%\Library                         # [cuda_compiler_version == "None" and win64]
        - >-
          {{ PYTHON }} -m pip install --no-deps --no-build-isolation -v .{{ extras }}
      ignore_run_exports:
        - cuda-version
        - cuda-python
      ignore_run_exports_from:
        - cuda-cudart-dev
      force_ignore_keys:
        - pytorch
    requirements:
      build:
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}                 # [cuda_compiler_version != "None"]
        - {{ stdlib('c') }}
        - cross-python_{{ target_platform }}     # [build_platform != target_platform]
        - python                                 # [build_platform != target_platform]
        - cython >=3.0.4,!=3.1.0,!=3.1.1         # [build_platform != target_platform]
        - cuda-profiler-api
      host:
        - python
        - cython >=3.0.4,!=3.1.0,!=3.1.1
        - setuptools >=77.0.3
        - tomli >=2.0.1  # [py < 311]
        - pip
        - cuda-version {{ cuda_compiler_version }}      # [cuda_compiler_version != "None"]
        - cuda-version {{ cuda_compiler_version_min }}  # [cuda_compiler_version == "None"]
        - cuda-cudart-dev
        - cuda-crt
        - cuda-bindings
        - cuda-profiler-api
      run:
        - python
        # pyproject.toml/dependencies
        - cuda-bindings
        - cuda-core >=0.3.2,<0.4
        - cuda-pathfinder >=1.3.2,<2.0
        - numpy >=1.25,<3
        - pywin32                         # [win64]
        # pyproject.toml/project/optional-dependencies/sysctkXX
        - cuda-bindings >=12.9.2,<13      # [(cuda_compiler_version or "").startswith("12")]
        - cuda-bindings >=13.0.1,<14      # [(cuda_compiler_version or "").startswith("13")]
        - cutensor >=2.3.1                # [cuda_compiler_version != "None"]
        # pyproject.toml/project/optional-dependencies/cuXX
        - cuda-core >=0.3.2,<0.4          # [cuda_compiler_version != "None"]
        - libcublas                       # [cuda_compiler_version != "None"]
        - cuda-nvrtc                      # [cuda_compiler_version != "None"]
        - cuda-cudart                     # [cuda_compiler_version != "None"]
        - libcudss 0.7.*                  # [cuda_compiler_version != "None"]
        - libcufft                        # [cuda_compiler_version != "None"]
        - libcurand                       # [cuda_compiler_version != "None"]
        - libcusolver                     # [cuda_compiler_version != "None"]
        - libcusparse                     # [cuda_compiler_version != "None"]
        - {{ pin_compatible('cuda-version', max_pin='x', min_pin='x') }}  # [cuda_compiler_version != "None"]
      run_constrained:
        - {{ pin_compatible('cuda-version', min_pin='x', max_pin=None) }}
        # pyproject.toml/project/optional-dependencies/cpu
        - libnvpl-fft0  >=0.3.0,<1.0a0
        - libnvpl-blas0 >=0.3.0,<1.0a0
        - mkl >=2024
        - cupy >=12.1.0
        - pytorch >=2.1.0
        # pyproject.toml/project/optional-dependencies/dx
        - numba-cuda >=0.18.1
        # pyproject.toml/project/optional-dependencies/cu12-dx
        - libmathdx >=0.2.3,<0.3
        - cuda-cccl >12.4.127
        - cuda-nvrtc !=12.4.*,!=12.5.0
        - cuda-version >=12.0,!=12.4,!=12.5.0
    test:
{% if is_gpu_available %}
      source_files:
        - examples/fft
        - examples/linalg
        - examples/sparse
        - tests/example_tests
{% endif %}
      requires:
        - cupy  # [cuda_compiler_version != "None"]
        - pip
        - pytest  # [cuda_compiler_version != "None"]
        - pytorch  # [(cuda_compiler_version != "None") and (not win)]
      {% if is_gpu_available %}
        - pytorch-gpu  # [not win]
      {% endif %}
        - scipy  # [cuda_compiler_version != "None"]
      imports:
        - nvmath
        - nvmath.fft
        - nvmath.linalg
        - nvmath.sparse
      commands:
        #  - pip check
{% if is_gpu_available %}
        - pytest tests/example_tests/matmul_tests/ -k "not cpu" -v -ra  # [cuda_compiler_version != "None"]
        - pytest tests/example_tests/fft_tests/ -k "not (cpu or callback)" -v -ra  # [cuda_compiler_version != "None"]
        - pytest tests/example_tests/sparse_tests/ -k "not cpu" -v -ra  # [cuda_compiler_version != "None"]
{% endif %}

  - name: nvmath-python-dx
    version: {{ version }}
    build:
      noarch: generic
      force_ignore_keys:
        - cuda_compiler_version
        - pytorch
      # There will be only one variant of this meta-package for all platforms, but we want
      # to run the tests with multiple variants of the base package.
      skip: true  # [cuda_compiler_version == "None"]
    requirements:
      run:
        - {{ pin_subpackage("nvmath-python", max_pin='x.x.x') }}
        - nvmath-python * cuda*
        # pyproject.toml/project/optional-dependencies/dx
        - numba
        - numba-cuda
        # pyproject.toml/project/optional-dependencies/cu12-dx
        - libmathdx
        - cuda-cccl
        - cuda-nvrtc
        # Device APIs need headers for JIT compile
        - libcurand-dev
    test:
      requires:
        - pip
{% if is_gpu_available %}
        - pytest
        - cffi
      source_files:
        - examples/device
        - examples/fft/*callback*.py
        - tests/example_tests
{% endif %}
      imports:
{% if is_gpu_available %}
        - nvmath.device
{% endif %}
        - nvmath
        - nvmath.fft
        - nvmath.linalg
        - nvmath.sparse
      commands:
        #  - pip check
{% if is_gpu_available %}
        - pytest tests/example_tests/device_tests/ -v -ra -k "simple or curand"
        - pytest tests/example_tests/fft_tests/ -k "callback" -v -ra
{% endif %}
    about:
      license: Apache-2.0
      license_file: LICENSE
      summary: Install this meta-package to use nvmath-python device features
      description: >-
        This is a meta-package which installs a some optional dependencies. The main package is nvmath-python.

  - name: nvmath-python-cpu
    version: {{ version }}
    build:
      force_ignore_keys:
        - cuda_compiler_version
        - pytorch
      # This meta-package will have only one variant for each platform, but we want to run
      # the tests with both cuda and non-cuda, so no skips here.
    requirements:
      run:
        - {{ pin_subpackage("nvmath-python", max_pin='x.x.x') }}
        - mkl  # [x86_64 or linux64]
        - libnvpl-fft0   # [arm64 or aarch64]
        - libnvpl-blas0  # [arm64 or aarch64]
    test:
      source_files:
        - examples/fft/example*cpu_execution.py
        - examples/linalg/generic/matmul/example*cpu.py
        - tests/example_tests
      requires:
        - pip
        - pytest
        - pytorch  # [not win]
      imports:
        - nvmath
        - nvmath.fft
        - nvmath.linalg
      commands:
        #  - pip check
        # We can't run tests with CUDA builds because CuPy complains about no GPUs
        - pytest tests/example_tests/fft_tests/ -k cpu -v -ra  # [cuda_compiler_version == "None"]
        # - pytest tests/example_tests/matmul_tests/ -k cpu -v -ra  # [cuda_compiler_version == "None"]
    about:
      license: Apache-2.0
      license_file: LICENSE
      summary: Install this meta-package to use nvmath-python cpu features
      description: >-
        This is a meta-package which installs a some optional dependencies. The main package is nvmath-python.

  - name: nvmath-python-distributed
    version: {{ version }}
    build:
      force_ignore_keys:
        - cuda_compiler_version
        - pytorch
      # There will be only one variant of this meta-package for all platforms, but we want
      # to run the tests with multiple variants of the base package.
      # distributed support currently requires CUDA 12
      skip: true  # [(cuda_compiler_version == "None") or win]
    requirements:
      run:
        - {{ pin_subpackage("nvmath-python", max_pin='x.x.x') }}
        - nvmath-python * cuda*
        - mpi4py
        - nccl >=2.24.3
        - libcublasmp >=0.6.0
        - libcufftmp
        - libcufftmp >= 12.1.3.2  # [(cuda_compiler_version or "").startswith("13")]
        - libnvshmem3 >=3.2.5
    test:
      source_files:
        - examples/distributed
        - tests/example_tests
      requires:
        - pip
        - pytest
        - pytorch  # [not win]
      {% if is_gpu_available %}
        - pytorch-gpu  # [not win]
      {% endif %}
      imports:
        - nvmath
        - nvmath.distributed
        - nvmath.distributed.fft
      commands:
        #  - pip check
      {% if is_gpu_available %}
        - mpiexec -n 2 pytest tests/example_tests/distributed_tests -v -ra -k "not sync"
      {% endif %}
    about:
      license: Apache-2.0
      license_file: LICENSE
      summary: Install this meta-package to use nvmath-python distributed features
      description: >-
        This is a meta-package which installs a some optional dependencies. The main package is nvmath-python.

about:
  home: https://developer.nvidia.com/nvmath-python
  license: Apache-2.0
  license_url: https://docs.nvidia.com/cuda/nvmath-python/latest/license.html
  license_file: LICENSE
  summary: NVIDIA Math Libraries for the Python Ecosystem
  description: >-
    nvmath-python aims to bring the power and performance of the NVIDIA math libraries to the Python ecosystem with intuitive, pythonic APIs. The ultimate goal is to provide users full access to all of the available library features in a variety of execution spaces.

    To enable optional features, install any of the following packages: nvmath-python-cpu, nvmath-python-dx.
  doc_url: https://docs.nvidia.com/cuda/nvmath-python
  dev_url: https://github.com/NVIDIA/nvmath-python

extra:
  feedstock-name: nvmath
  recipe-maintainers:
    - conda-forge/cuda
    - carterbox
    - leofang
